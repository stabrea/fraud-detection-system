"""
Advanced feature engineering for fraud detection.

Generates behavioral and statistical features that capture
anomalous transaction patterns: velocity checks, geographic
anomalies, amount patterns, and temporal signals.
"""

from __future__ import annotations

from typing import Optional

import numpy as np
import pandas as pd


class FeatureEngineer:
    """Generates advanced fraud-signal features from preprocessed data.

    Works as a second-stage transformer after ``TransactionPreprocessor``,
    adding velocity, geographic, amount-pattern, and time-pattern features.
    """

    def __init__(
        self,
        velocity_windows: Optional[list[int]] = None,
        amount_percentile_threshold: float = 95.0,
    ) -> None:
        """
        Args:
            velocity_windows: Rolling window sizes (in number of
                transactions) for velocity calculations. Defaults
                to ``[3, 5, 10]``.
            amount_percentile_threshold: Percentile above which an
                amount is flagged as unusually high.
        """
        self._velocity_windows: list[int] = velocity_windows or [3, 5, 10]
        self._amount_pct_threshold: float = amount_percentile_threshold
        self._fitted: bool = False
        self._global_amount_p95: float = 0.0
        self._category_amount_stats: dict[str, dict[str, float]] = {}
        self._customer_location_map: dict[str, set[str]] = {}

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Fit on training data and return feature-enriched DataFrame.

        Args:
            df: Preprocessed transaction DataFrame.

        Returns:
            DataFrame with additional feature columns.
        """
        df = df.copy()
        self._fit_statistics(df)
        df = self._add_velocity_features(df)
        df = self._add_geographic_features(df)
        df = self._add_amount_pattern_features(df)
        df = self._add_time_pattern_features(df)
        df = self._add_risk_indicators(df)
        self._fitted = True
        return df

    def transform(self, df: pd.DataFrame) -> pd.DataFrame:
        """Transform new data using fitted statistics.

        Args:
            df: Preprocessed transaction DataFrame.

        Returns:
            Feature-enriched DataFrame.

        Raises:
            RuntimeError: If called before ``fit_transform``.
        """
        if not self._fitted:
            raise RuntimeError(
                "FeatureEngineer not fitted. Call fit_transform first."
            )
        df = df.copy()
        df = self._add_velocity_features(df)
        df = self._add_geographic_features(df)
        df = self._add_amount_pattern_features(df)
        df = self._add_time_pattern_features(df)
        df = self._add_risk_indicators(df)
        return df

    def get_feature_columns(self) -> list[str]:
        """Return names of all features generated by this engineer."""
        cols: list[str] = []

        # Velocity features
        for w in self._velocity_windows:
            cols.append(f"velocity_{w}_mean")
            cols.append(f"velocity_{w}_std")
            cols.append(f"velocity_{w}_max")

        cols.extend([
            # Geographic
            "location_count",
            "is_new_location",
            # Amount patterns
            "amount_is_round",
            "amount_above_p95",
            "amount_ratio_to_category_mean",
            # Time patterns
            "hour_sin",
            "hour_cos",
            "transactions_same_hour",
            # Risk indicators
            "rapid_succession",
            "high_amount_night",
            "risk_score_heuristic",
        ])
        return cols

    # ------------------------------------------------------------------
    # Internal: fit
    # ------------------------------------------------------------------

    def _fit_statistics(self, df: pd.DataFrame) -> None:
        """Compute global statistics used by feature generators."""
        if "amount" in df.columns:
            self._global_amount_p95 = float(
                np.percentile(df["amount"].dropna(), self._amount_pct_threshold)
            )

        # Per-category amount statistics
        if "merchant_category" in df.columns and "amount" in df.columns:
            grouped = df.groupby("merchant_category")["amount"]
            for cat, group in grouped:
                self._category_amount_stats[str(cat)] = {
                    "mean": float(group.mean()),
                    "std": float(group.std()) if len(group) > 1 else 1.0,
                }

        # Known customer locations
        if "customer_id" in df.columns and "location" in df.columns:
            for cid, group in df.groupby("customer_id"):
                self._customer_location_map[str(cid)] = set(
                    group["location"].dropna().unique()
                )

    # ------------------------------------------------------------------
    # Internal: velocity features
    # ------------------------------------------------------------------

    def _add_velocity_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Rolling-window velocity statistics per customer."""
        if "customer_id" not in df.columns or "amount" not in df.columns:
            for w in self._velocity_windows:
                df[f"velocity_{w}_mean"] = 0.0
                df[f"velocity_{w}_std"] = 0.0
                df[f"velocity_{w}_max"] = 0.0
            return df

        # Sort by customer and time for correct rolling behaviour
        sort_cols = ["customer_id"]
        if "timestamp" in df.columns:
            sort_cols.append("timestamp")
        df = df.sort_values(sort_cols).reset_index(drop=True)

        grouped = df.groupby("customer_id")["amount"]
        for w in self._velocity_windows:
            rolling = grouped.transform(
                lambda s: s.rolling(window=w, min_periods=1).mean()
            )
            df[f"velocity_{w}_mean"] = rolling

            rolling_std = grouped.transform(
                lambda s: s.rolling(window=w, min_periods=1).std().fillna(0)
            )
            df[f"velocity_{w}_std"] = rolling_std

            rolling_max = grouped.transform(
                lambda s: s.rolling(window=w, min_periods=1).max()
            )
            df[f"velocity_{w}_max"] = rolling_max

        return df

    # ------------------------------------------------------------------
    # Internal: geographic features
    # ------------------------------------------------------------------

    def _add_geographic_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Detect geographic anomalies per customer."""
        if "customer_id" not in df.columns or "location" not in df.columns:
            df["location_count"] = 0
            df["is_new_location"] = 0
            return df

        # Number of distinct locations per customer (in this dataset slice)
        loc_count = df.groupby("customer_id")["location"].transform("nunique")
        df["location_count"] = loc_count

        # Flag transactions from locations not seen during training
        def _check_new_location(row: pd.Series) -> int:
            cid = str(row["customer_id"])
            loc = str(row.get("location", ""))
            known = self._customer_location_map.get(cid, set())
            if not known:
                return 0
            return int(loc not in known)

        df["is_new_location"] = df.apply(_check_new_location, axis=1)
        return df

    # ------------------------------------------------------------------
    # Internal: amount pattern features
    # ------------------------------------------------------------------

    def _add_amount_pattern_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Detect suspicious amount patterns."""
        if "amount" not in df.columns:
            df["amount_is_round"] = 0
            df["amount_above_p95"] = 0
            df["amount_ratio_to_category_mean"] = 0.0
            return df

        # Round-number transactions (common in synthetic fraud)
        df["amount_is_round"] = (df["amount"] % 100 == 0).astype(int)

        # Unusually high amounts
        df["amount_above_p95"] = (
            df["amount"] > self._global_amount_p95
        ).astype(int)

        # Ratio to category mean
        if "merchant_category" in df.columns:
            df["amount_ratio_to_category_mean"] = df.apply(
                lambda r: (
                    r["amount"]
                    / self._category_amount_stats.get(
                        str(r["merchant_category"]), {}
                    ).get("mean", r["amount"] or 1.0)
                )
                if r["amount"] > 0
                else 0.0,
                axis=1,
            )
        else:
            df["amount_ratio_to_category_mean"] = 0.0

        return df

    # ------------------------------------------------------------------
    # Internal: time pattern features
    # ------------------------------------------------------------------

    def _add_time_pattern_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Cyclical time encoding and same-hour frequency."""
        if "hour_of_day" not in df.columns:
            df["hour_sin"] = 0.0
            df["hour_cos"] = 0.0
            df["transactions_same_hour"] = 0
            return df

        # Cyclical encoding preserves proximity (hour 23 is near hour 0)
        df["hour_sin"] = np.sin(2 * np.pi * df["hour_of_day"] / 24)
        df["hour_cos"] = np.cos(2 * np.pi * df["hour_of_day"] / 24)

        # Count of transactions in the same hour (proxy for burst activity)
        if "customer_id" in df.columns:
            df["transactions_same_hour"] = df.groupby(
                ["customer_id", "hour_of_day"]
            )["hour_of_day"].transform("count")
        else:
            df["transactions_same_hour"] = df.groupby("hour_of_day")[
                "hour_of_day"
            ].transform("count")

        return df

    # ------------------------------------------------------------------
    # Internal: composite risk indicators
    # ------------------------------------------------------------------

    def _add_risk_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Combine signals into heuristic risk indicators."""
        # Rapid succession: high transaction frequency in short window
        df["rapid_succession"] = (
            df.get("transaction_frequency", pd.Series(0, index=df.index)) > 10
        ).astype(int)

        # High amount at night
        is_night = df.get(
            "is_night_transaction", pd.Series(0, index=df.index)
        )
        is_high = df.get("amount_above_p95", pd.Series(0, index=df.index))
        df["high_amount_night"] = (is_night & is_high).astype(int)

        # Simple heuristic risk score (0-1 scale)
        signals = [
            df.get("is_night_transaction", pd.Series(0, index=df.index)) * 0.15,
            df.get("amount_above_p95", pd.Series(0, index=df.index)) * 0.25,
            df.get("amount_is_round", pd.Series(0, index=df.index)) * 0.10,
            df.get("is_new_location", pd.Series(0, index=df.index)) * 0.20,
            df.get("rapid_succession", pd.Series(0, index=df.index)) * 0.15,
            df.get("high_amount_night", pd.Series(0, index=df.index)) * 0.15,
        ]
        df["risk_score_heuristic"] = sum(signals).clip(upper=1.0)

        return df
